# Copyright (c) OpenMMLab. All rights reserved.
import torch
import torch.nn.functional as F


class Grad:
    """GradCAM class helps create visualization results.

    Visualization results are blended by heatmaps and input images.
    This class is modified from
    https://github.com/facebookresearch/SlowFast/blob/master/slowfast/visualization/gradcam_utils.py # noqa
    For more information about GradCAM, please visit:
    https://arxiv.org/pdf/1610.02391.pdf
    """

    def __init__(self, model, cfg, target_layer_name):
        """Create GradCAM class with recognizer, target layername & colormap.

        Args:
            model (nn.Module): the recognizer model to be used.
            target_layer_name (list): name of convolutional layer to
                be used to get gradients and feature maps from for creating
                localization maps.
            colormap (Optional[str]): matplotlib colormap used to create
                heatmap. Default: 'viridis'. For more information, please visit
                https://matplotlib.org/3.3.0/tutorials/colors/colormaps.html
        """
        #from ..models.recognizers import Recognizer2D, Recognizer3D
        #if isinstance(model, Recognizer2D):
        #    self.is_recognizer2d = True
        #elif isinstance(model, Recognizer3D):
        #    self.is_recognizer2d = False
        #else:
        #    raise ValueError(
        #        'GradCAM utils only support Recognizer2D & Recognizer3D.')

        self.model = model
        self.model.eval()
        self.target_gradients = {}
        self.target_activations = {}

        import matplotlib.pyplot as plt
        self.data_mean = torch.tensor(cfg.img_norm_cfg['mean'])
        self.data_std = torch.tensor(cfg.img_norm_cfg['std'])
        for layer in target_layer_name:
            self._register_hooks(layer)

    def _register_hooks(self, layer_name):
        """Register forward and backward hook to a layer, given layer_name, to
        obtain gradients and activations.

        Args:
            layer_name (str): name of the layer.
        """

        def get_gradients(module, grad_input, grad_output):
            self.target_gradients[layer_name] = grad_output[0].detach()

        def get_activations(module, input, output):
            # for mvit:
            #self.target_activations = output[0].clone().detach()
            # for other module
            if isinstance(output, tuple):
                output = output[0]
            self.target_activations[layer_name] = output.clone().detach()

        layer_ls = layer_name.split('.')
        prev_module = self.model
        for layer in layer_ls:
            prev_module = prev_module._modules[layer]
        target_layer = prev_module
        target_layer.register_forward_hook(get_activations)
        target_layer.register_backward_hook(get_gradients)


    def reshape_transform(tensor, height=7, width=7):
        result = tensor[:,  :  , :].reshape(tensor.size(0),
            height, width, tensor.size(2))

        # Bring the channels to the first dimension, like in CNNs.
        result = result.transpose(2, 3).transpose(1, 2)
        return result
    def get_grad(self, inputs, use_labels):
        """Calculate localization map for all inputs with Grad-CAM.

        Args:
            inputs (dict): model inputs, generated by test pipeline,
                at least including two keys, ``imgs`` and ``label``.
            use_labels (bool): Whether to use given labels to generate
                localization map. Labels are in ``inputs['label']``.
            
        """
        inputs['imgs'] = inputs['imgs'].clone()

        # model forward & backward
        preds = self.model(gradcam=True, **inputs)
        if use_labels:
            labels = inputs['label']
            if labels.ndim == 1:
                labels = labels.unsqueeze(-1)
            score = torch.gather(preds, dim=1, index=labels)
        else:
            score = torch.max(preds, dim=-1)[0]
            pred_cls = torch.argmax(preds, dim=-1)[0]
        self.model.zero_grad()
        score = torch.sum(score)
        score.backward()

        

        gradients = self.target_gradients
        activations = self.target_activations
        

        return gradients, activations, pred_cls

    

    def __call__(self, inputs, use_labels=False, alpha=0.5, is_transformer=False, num_frms=0, img_size=-1, patch_size=-1):
        """Visualize the localization maps on their corresponding inputs as
        heatmap, using Grad-CAM.

        Generate visualization results for **ALL CROPS**.
        For example, for I3D model, if `clip_len=32, num_clips=10` and
        use `ThreeCrop` in test pipeline, then for every model inputs,
        there are 960(32*10*3) images generated.

        Args:
            inputs (dict): model inputs, generated by test pipeline,
                at least including two keys, ``imgs`` and ``label``.
            use_labels (bool): Whether to use given labels to generate
                localization map. Labels are in ``inputs['label']``.
            alpha (float): transparency level of the heatmap,
                in the range [0, 1].
        Returns:
            blended_imgs (torch.Tensor): Visualization results, blended by
                localization maps and model inputs.
            preds (torch.Tensor): Model predictions for inputs.
        """

        # localization_map shape [B, T, H, W]
        # preds shape [batch_size, num_classes]
        gradients, activations, pred_cls = self.get_grad(inputs, use_labels=use_labels)
        
        
        return gradients, activations, inputs['label'], pred_cls.detach().cpu()
